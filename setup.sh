#!/bin/bash

echo "ðŸš€ Setting up Make It Heavy with Ollama..."
echo ""

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama is not installed."
    echo "ðŸ“¥ Installing Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
    echo "âœ… Ollama installed successfully!"
else
    echo "âœ… Ollama is already installed."
fi

# Check if Ollama is running
if ! curl -s http://localhost:11434/api/tags &> /dev/null; then
    echo "ðŸ”„ Starting Ollama server..."
    ollama serve &
    sleep 3
    echo "âœ… Ollama server started!"
else
    echo "âœ… Ollama server is already running."
fi

# Check if the default model is installed
if ! ollama list | grep -q "llama3.2:3b"; then
    echo "ðŸ“¥ Pulling default model (llama3.2:3b)..."
    ollama pull llama3.2:3b
    echo "âœ… Model downloaded successfully!"
else
    echo "âœ… Default model is already installed."
fi

# Install Python dependencies
echo "ðŸ“¦ Installing Python dependencies..."
pip install -r requirements.txt
echo "âœ… Dependencies installed!"

echo ""
echo "ðŸŽ‰ Setup complete! You can now run:"
echo "  python main.py          # Single agent mode"
echo "  python make_it_heavy.py # Multi-agent orchestrator mode"
echo ""
echo "ðŸ’¡ Make sure Ollama is running: ollama serve" 